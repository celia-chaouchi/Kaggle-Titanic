{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ee2f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/celia/Desktop/GitHub/Kaggle-Titanic/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c233d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e053c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d9a3a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2c6ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c503885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   891.000000  891.000000\n",
       "mean    446.000000    0.383838\n",
       "std     257.353842    0.486592\n",
       "min       1.000000    0.000000\n",
       "25%     223.500000    0.000000\n",
       "50%     446.000000    0.000000\n",
       "75%     668.500000    1.000000\n",
       "max     891.000000    1.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c74565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0fbf7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = train.isnull().any(axis=1)\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edddcd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "male      577\n",
       "female    314\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Sex\"].value_counts(dropna=False) #permets d'avoir les pseudo valeurs NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f7e4477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Fare', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#On enlève les valeurs qui ne nous servent à rien\n",
    "train=train.drop(columns=[\"Name\",\"Ticket\",\"Cabin\"])\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3a084e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train=pd.get_dummies(train)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ac397d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train.drop(columns=\"Sex_male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea56cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Survived']\n",
    "X = train.drop(columns =['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb046650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3691296549.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, num_cols] = pd.DataFrame(imputer.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3691296549.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0.]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, num_cols] = pd.DataFrame(imputer.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "from sklearn.experimental import (enable_iterative_imputer,)\n",
    "from sklearn import impute\n",
    "num_cols =[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Sex_female\"]\n",
    "imputer = impute.IterativeImputer ()\n",
    "X_train.loc[:, num_cols] = pd.DataFrame(imputer.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "X_test.loc[:, num_cols] = pd.DataFrame(imputer.transform(X_test[num_cols]), columns=num_cols, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5d8913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3304568218.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.63788124  0.80326712  0.80326712 -0.41730706 -0.41730706 -1.63788124\n",
      " -0.41730706  0.80326712  0.80326712 -0.41730706 -1.63788124 -0.41730706\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124 -0.41730706 -0.41730706\n",
      "  0.80326712 -1.63788124  0.80326712  0.80326712 -1.63788124 -0.41730706\n",
      " -1.63788124 -0.41730706 -0.41730706  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712 -0.41730706 -0.41730706  0.80326712 -1.63788124  0.80326712\n",
      " -1.63788124  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      " -0.41730706 -1.63788124 -1.63788124 -0.41730706  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      "  0.80326712 -0.41730706  0.80326712  0.80326712 -1.63788124 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712 -1.63788124\n",
      " -1.63788124 -0.41730706  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -0.41730706  0.80326712 -1.63788124  0.80326712\n",
      " -1.63788124 -1.63788124  0.80326712  0.80326712 -0.41730706 -1.63788124\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -1.63788124 -0.41730706\n",
      " -1.63788124 -1.63788124 -0.41730706  0.80326712 -0.41730706 -0.41730706\n",
      " -1.63788124  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712\n",
      " -1.63788124  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706 -0.41730706 -0.41730706  0.80326712 -1.63788124 -0.41730706\n",
      "  0.80326712 -1.63788124 -0.41730706  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706  0.80326712 -1.63788124 -0.41730706\n",
      "  0.80326712 -1.63788124  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124 -1.63788124 -0.41730706 -1.63788124\n",
      " -0.41730706 -0.41730706  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712 -1.63788124 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      " -0.41730706  0.80326712 -0.41730706  0.80326712 -1.63788124  0.80326712\n",
      " -0.41730706  0.80326712 -1.63788124 -1.63788124 -1.63788124 -1.63788124\n",
      " -1.63788124  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      " -1.63788124  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      " -0.41730706 -1.63788124  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712 -1.63788124 -0.41730706\n",
      " -0.41730706 -1.63788124  0.80326712  0.80326712 -1.63788124 -1.63788124\n",
      " -1.63788124  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      " -0.41730706  0.80326712 -0.41730706  0.80326712  0.80326712 -1.63788124\n",
      " -0.41730706  0.80326712 -1.63788124  0.80326712  0.80326712 -1.63788124\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      " -0.41730706  0.80326712  0.80326712  0.80326712  0.80326712 -1.63788124\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706 -1.63788124\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712 -0.41730706  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      " -1.63788124  0.80326712  0.80326712 -0.41730706  0.80326712 -0.41730706\n",
      "  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712 -1.63788124\n",
      "  0.80326712 -0.41730706 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      " -0.41730706 -0.41730706 -1.63788124 -1.63788124  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      " -1.63788124  0.80326712 -0.41730706 -1.63788124 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706 -0.41730706  0.80326712 -1.63788124  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712 -1.63788124\n",
      "  0.80326712 -0.41730706 -1.63788124 -0.41730706 -0.41730706 -1.63788124\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712 -0.41730706  0.80326712 -1.63788124  0.80326712 -0.41730706\n",
      " -0.41730706 -1.63788124 -1.63788124 -1.63788124 -1.63788124  0.80326712\n",
      "  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124 -1.63788124 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -0.41730706 -0.41730706\n",
      "  0.80326712 -1.63788124  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706  0.80326712 -1.63788124 -0.41730706 -1.63788124  0.80326712\n",
      " -1.63788124  0.80326712 -0.41730706 -1.63788124  0.80326712  0.80326712\n",
      " -1.63788124 -1.63788124 -1.63788124  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712 -1.63788124\n",
      " -1.63788124  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712 -0.41730706  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706 -1.63788124  0.80326712 -1.63788124  0.80326712  0.80326712\n",
      " -0.41730706 -0.41730706 -0.41730706  0.80326712  0.80326712 -1.63788124\n",
      "  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712 -1.63788124\n",
      " -1.63788124 -1.63788124  0.80326712  0.80326712  0.80326712 -1.63788124\n",
      "  0.80326712 -1.63788124 -1.63788124  0.80326712 -1.63788124 -1.63788124\n",
      " -1.63788124  0.80326712 -1.63788124 -1.63788124 -1.63788124  0.80326712\n",
      " -0.41730706  0.80326712  0.80326712 -1.63788124 -1.63788124  0.80326712\n",
      " -0.41730706 -1.63788124  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712\n",
      " -0.41730706  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      " -0.41730706  0.80326712  0.80326712  0.80326712  0.80326712 -0.41730706\n",
      " -0.41730706 -1.63788124 -1.63788124 -0.41730706  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -1.63788124 -0.41730706  0.80326712  0.80326712\n",
      " -0.41730706  0.80326712  0.80326712 -1.63788124  0.80326712 -1.63788124\n",
      " -1.63788124  0.80326712 -0.41730706  0.80326712  0.80326712 -0.41730706\n",
      " -1.63788124 -0.41730706  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706 -0.41730706  0.80326712 -0.41730706  0.80326712 -0.41730706\n",
      "  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712 -1.63788124\n",
      " -0.41730706  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712\n",
      " -0.41730706  0.80326712  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712 -1.63788124  0.80326712 -1.63788124 -1.63788124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, cols] = pd.DataFrame(sca.fit_transform(X_train[cols]), columns=cols, index=X_train.index)\n",
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3304568218.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.47416141 -0.47416141  0.34868694  0.34868694  0.34868694 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      "  1.17153529 -0.47416141  0.34868694 -0.47416141 -0.47416141  2.81723199\n",
      " -0.47416141  0.34868694  0.34868694  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      "  0.34868694 -0.47416141  0.34868694  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  1.99438364 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  1.17153529 -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  2.81723199 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      "  1.99438364 -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141\n",
      "  2.81723199 -0.47416141  0.34868694 -0.47416141 -0.47416141  1.17153529\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  1.17153529 -0.47416141  0.34868694\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141  6.1086254\n",
      "  0.34868694  0.34868694  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  2.81723199 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694  1.99438364\n",
      " -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  2.81723199 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      "  1.17153529 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  1.99438364  0.34868694  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141  2.81723199\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694  3.64008034\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  1.99438364 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  2.81723199  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  6.1086254  -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  1.17153529  0.34868694  1.17153529 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141  6.1086254   1.17153529 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  1.17153529  2.81723199  2.81723199\n",
      " -0.47416141  1.17153529 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      "  3.64008034 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  1.17153529 -0.47416141  0.34868694  1.99438364 -0.47416141 -0.47416141\n",
      "  1.99438364  1.17153529 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141  1.17153529 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  2.81723199  0.34868694  0.34868694  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141  1.17153529\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  1.17153529\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694  1.17153529 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  3.64008034  6.1086254  -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      "  2.81723199 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  6.1086254   0.34868694  0.34868694\n",
      "  0.34868694  0.34868694  0.34868694 -0.47416141  2.81723199 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694  0.34868694  2.81723199\n",
      "  0.34868694  1.99438364 -0.47416141  0.34868694  6.1086254  -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694  1.17153529 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141  1.99438364 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141  3.64008034 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  1.99438364 -0.47416141  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141\n",
      "  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      "  1.99438364 -0.47416141 -0.47416141 -0.47416141 -0.47416141  6.1086254\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141  1.17153529 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141  1.17153529\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141  2.81723199 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141  1.17153529  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694  3.64008034\n",
      " -0.47416141 -0.47416141  1.17153529  0.34868694 -0.47416141]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, cols] = pd.DataFrame(sca.fit_transform(X_train[cols]), columns=cols, index=X_train.index)\n",
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3304568218.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.80326712 -0.41730706  0.80326712 -0.41730706  0.80326712 -1.63788124\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706 -1.63788124 -1.63788124  0.80326712\n",
      " -0.41730706 -1.63788124  0.80326712 -1.63788124  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124 -0.41730706  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712 -1.63788124\n",
      "  0.80326712 -1.63788124 -0.41730706 -1.63788124 -0.41730706  0.80326712\n",
      "  0.80326712 -0.41730706 -0.41730706 -1.63788124  0.80326712 -0.41730706\n",
      " -0.41730706  0.80326712  0.80326712 -1.63788124 -0.41730706 -1.63788124\n",
      " -1.63788124 -1.63788124  0.80326712  0.80326712  0.80326712 -1.63788124\n",
      " -0.41730706  0.80326712  0.80326712 -0.41730706 -1.63788124  0.80326712\n",
      " -1.63788124 -1.63788124 -1.63788124 -1.63788124 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -0.41730706  0.80326712 -1.63788124  0.80326712\n",
      " -1.63788124  0.80326712  0.80326712  0.80326712 -0.41730706 -1.63788124\n",
      "  0.80326712 -1.63788124 -1.63788124  0.80326712 -1.63788124 -1.63788124\n",
      " -1.63788124  0.80326712 -1.63788124 -0.41730706 -0.41730706  0.80326712\n",
      " -0.41730706 -1.63788124 -1.63788124 -0.41730706  0.80326712 -1.63788124\n",
      " -1.63788124 -1.63788124  0.80326712  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706  0.80326712 -1.63788124  0.80326712 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706 -0.41730706 -0.41730706\n",
      "  0.80326712 -0.41730706 -0.41730706 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -0.41730706  0.80326712  0.80326712 -1.63788124\n",
      " -0.41730706 -1.63788124  0.80326712 -1.63788124 -0.41730706 -1.63788124\n",
      "  0.80326712  0.80326712 -1.63788124 -0.41730706 -1.63788124  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712 -1.63788124\n",
      " -0.41730706  0.80326712  0.80326712  0.80326712 -1.63788124 -1.63788124\n",
      " -0.41730706  0.80326712 -1.63788124 -0.41730706  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712 -0.41730706 -1.63788124 -1.63788124 -0.41730706\n",
      " -1.63788124  0.80326712  0.80326712  0.80326712 -0.41730706  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712\n",
      " -1.63788124  0.80326712 -1.63788124  0.80326712  0.80326712  0.80326712\n",
      " -0.41730706 -1.63788124 -0.41730706  0.80326712  0.80326712 -0.41730706\n",
      "  0.80326712 -1.63788124  0.80326712 -0.41730706  0.80326712 -1.63788124\n",
      " -0.41730706  0.80326712 -0.41730706 -1.63788124  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712 -1.63788124 -0.41730706\n",
      "  0.80326712 -0.41730706  0.80326712  0.80326712  0.80326712  0.80326712\n",
      "  0.80326712  0.80326712  0.80326712 -1.63788124  0.80326712 -0.41730706\n",
      "  0.80326712  0.80326712 -1.63788124  0.80326712  0.80326712 -1.63788124\n",
      " -0.41730706 -0.41730706 -1.63788124 -1.63788124 -0.41730706  0.80326712\n",
      " -1.63788124 -1.63788124  0.80326712 -1.63788124]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, cols] = pd.DataFrame(sca.transform(X_test[cols]), columns=cols, index=X_test.index)\n",
      "/var/folders/fr/v8dj2xfs6hj066bhsf2166tw0000gp/T/ipykernel_19826/3304568218.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141  1.17153529 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      "  1.99438364 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141  1.99438364 -0.47416141 -0.47416141  1.99438364 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  1.17153529  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  1.17153529  0.34868694  0.34868694  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694  0.34868694  1.17153529\n",
      " -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  2.81723199 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  2.81723199 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694  0.34868694\n",
      "  1.17153529 -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694  2.81723199 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      "  0.34868694  2.81723199 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  0.34868694 -0.47416141  1.99438364  1.99438364\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      "  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141  0.34868694\n",
      "  0.34868694 -0.47416141  0.34868694  1.17153529 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141  0.34868694 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141  1.17153529 -0.47416141 -0.47416141  0.34868694\n",
      " -0.47416141  0.34868694 -0.47416141  0.34868694 -0.47416141 -0.47416141\n",
      " -0.47416141 -0.47416141 -0.47416141 -0.47416141]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, cols] = pd.DataFrame(sca.transform(X_test[cols]), columns=cols, index=X_test.index)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sca = StandardScaler()\n",
    "cols = \"Pclass,Age,SibSp,Fare\".split(\",\")\n",
    "sca = StandardScaler()\n",
    "X_train.loc[:, cols] = pd.DataFrame(sca.fit_transform(X_train[cols]), columns=cols, index=X_train.index)\n",
    "X_test.loc[:, cols] = pd.DataFrame(sca.transform(X_test[cols]), columns=cols, index=X_test.index)\n",
    "X_train = X_train[cols].copy()\n",
    "X_test = X_test[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "41d2e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_titanic(df):\n",
    "    df = df.drop(columns=[\"Name\",\"Ticket\",\"Cabin\"]).pipe(pd.get_dummies,drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "39588242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_X_y(df, y_col, size=0.3, std_cols=None):\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "    X_train, X_test, y_train, _test = model_selection. train_test_split(X,y, test_size=size,random_state=42)\n",
    "    cols = X.columns\n",
    "    num_cols =[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "    fi = impute.IterativeImputer ()\n",
    "    X_test. loc[:, num_cols] = fi. transform(X_test [num_cols])\n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        X_train.loc[:, std_cols] = std.fit_transform(X_train[std_cols])\n",
    "        X_test.loc[:, std_cols] = std.transform(X_test[std_cols])\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_df = tweak_titanic(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b59b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4315068493150685"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "bm = DummyClassifier(strategy=\"uniform\")\n",
    "bm.fit(X_train, y_train)\n",
    "bm.score(X_test, y_test) # accuracy = TP/TP+FP\n",
    "from sklearn import metrics\n",
    "metrics.precision_score(y_test, bm.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90d273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([140, 128]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(bm.predict(X_test), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b3c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier        AUC: 0.500 STD: 0.00\n",
      "LogisticRegression     AUC: 0.734 STD: 0.06\n",
      "DecisionTreeClassifier AUC: 0.661 STD: 0.06\n",
      "KNeighborsClassifier   AUC: 0.760 STD: 0.09\n",
      "GaussianNB             AUC: 0.711 STD: 0.06\n",
      "SVC                    AUC: 0.728 STD: 0.06\n",
      "RandomForestClassifier AUC: 0.770 STD: 0.07\n",
      "XGBClassifier          AUC: 0.767 STD: 0.06\n"
     ]
    }
   ],
   "source": [
    "#nous réalisons une validation croisée à k-plis et on teste quel modèle est le plus performant \n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn. linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "for model in [DummyClassifier,LogisticRegression,DecisionTreeClassifier,KNeighborsClassifier,GaussianNB,SVC,RandomForestClassifier,XGBClassifier]:\n",
    "    cls = model()\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    s = model_selection.cross_val_score(cls, X, y, scoring=\"roc_auc\", cv=kfold)\n",
    "    print(f\"{model.__name__:22} AUC: {s.mean():.3f} STD: {s.std():.2f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf033e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlxtend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StackingClassifier\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clfs = \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKNeighborsClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mGaussianNB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m stack = StackingClassifier(classifiers = clfs, meta_classifier=LogisticRegression())\n\u001b[32m      4\u001b[39m kfold = model_selection.KFold(n_splits=\u001b[32m10\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlxtend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StackingClassifier\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clfs = [\u001b[43mx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [LogisticRegression(),DecisionTreeClassifier(),KNeighborsClassifier(),GaussianNB(),SVC(), RandomForestClassifier()]]\n\u001b[32m      3\u001b[39m stack = StackingClassifier(classifiers = clfs, meta_classifier=LogisticRegression())\n\u001b[32m      4\u001b[39m kfold = model_selection.KFold(n_splits=\u001b[32m10\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'LogisticRegression' object is not callable"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "clfs = [x() for x in [LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, RandomForestClassifier]]\n",
    "stack = StackingClassifier(classifiers = clfs, meta_classifier=LogisticRegression(),use_probas=True)\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "s= model_selection.cross_val_score (stack, X, y, scoring = \"roc_auc\", cv=kfold)\n",
    "print (f\"{stack.__class__.__name__}\" f\"AUC: {s.mean():.3f} STD: {s.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bf945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66777aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54310104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b3513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b14250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dc786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ae91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119be0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b129892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07e864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34b291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330de562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f18378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50720c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99a673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d0d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777ea1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
